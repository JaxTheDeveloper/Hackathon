1
1

00:00:00,030  -->  00:00:06,230
Hey! Here we are again and in this lecture we
will continue building our real-world
3

2

00:00:06,230  -->  00:00:14,599
motion detection program. Now before I go
and write the code ,I would first like to
5

3

00:00:14,599  -->  00:00:20,880
explain to you the architecture of
the program that we'll be building. So how
7

4

00:00:20,880  -->  00:00:25,920
this program is able to detect motion in
the video. And I assume you already know
9

5

00:00:25,920  -->  00:00:32,640
how to build this script, so we built
this in the previous lectures, and what
11

6

00:00:32,640  -->  00:00:44,250
the script does is that in case you've
missed it. Hey! So what this does is it
13

7

00:00:44,250  -->  00:00:51,600
triggers the video as you saw from the
computer webcam, so we were processing
15

8

00:00:51,600  -->  00:00:57,590
frames here in this while loop and so on.
So you know this I will not go through
17

9

00:00:57,590  -->  00:01:04,229
them right now, so what we need to do
next is we need to process those frames
19

10

00:01:04,229  -->  00:01:09,330
that are being iterated in this while
loop, and I've got some pictures here to
21

11

00:01:09,330  -->  00:01:15,330
illustrate my ideas, my concepts. Let me
go to the directory where they are located.
23

12

00:01:15,330  -->  00:01:22,110
So what this motion detection
program will do is it will trigger the
25

13

00:01:22,110  -->  00:01:26,970
webcam just like our current script does
and one condition for the program to
27

14

00:01:26,970  -->  00:01:31,740
work well is that once you trigger the
webcam the first frame of the video
29

15

00:01:31,740  -->  00:01:37,290
should be a static background.
So if you're planning to use this
31

16

00:01:37,290  -->  00:01:44,549
program let's say you'll set up a webcam
on a laptop or as Raspberry Pi server. Let's
33

17

00:01:44,549  -->  00:01:50,869
say you want to detect the movement of
of a certain animal in an area, so first
35

18

00:01:50,869  -->  00:01:56,189
you'd want to capture, to trigger
the camera while the background is
37

19

00:01:56,189  -->  00:02:01,439
static and then you want to use this
background as a base image so that you
39

20

00:02:01,439  -->  00:02:06,119
can compare the other images and then
Python can detect if there is a change
41

21

00:02:06,119  -->  00:02:08,729
between the first frame
and the next frames.
43

22

00:02:08,729  -->  00:02:14,810
So that's one thing you need to do
and so this is an example of background.
45

23

00:02:14,810  -->  00:02:22,290
And then something, the animal will
appear on your camera. Okay, and then what
47

24

00:02:22,290  -->  00:02:28,190
you have to write in your script in the
program is that first we would want to
49

25

00:02:28,190  -->  00:02:33,989
gray out this image, so the background
image at the current frame of the camera.
51

26

00:02:33,989  -->  00:02:38,940
So you'll store the first frame of the
video capture in a variable, and then you
53

27

00:02:38,940  -->  00:02:44,940
will convert that frame to a grayscale
image and then the while loop will
55

28

00:02:44,940  -->  00:02:49,709
go through the current frames and you'll do
the same for the current frames, so you'll
57

29

00:02:49,709  -->  00:02:55,440
convert them to grayscale, and then what
you do to these two grayscale images of
59

30

00:02:55,440  -->  00:03:00,660
the current iteration of the loop, you'll
apply the difference between them.
61

31

00:03:00,660  -->  00:03:06,000
So this is a difference an example of
a difference frame, of a delta frame if you
63

32

00:03:06,000  -->  00:03:10,680
can say like that. In this particular
image you'll notice that behind me, there
65

33

00:03:10,680  -->  00:03:16,319
is a lamp of the room and normally you
wouldn't be able to see the lamp, but Python
67

34

00:03:16,319  -->  00:03:21,090
is actually making the difference
between the frame where I was appearing
69

35

00:03:21,090  -->  00:03:27,030
and the background frame where the lamp
is visible, so it comes up with this gray
71

36

00:03:27,030  -->  00:03:32,150
image where each pixel has a certain
value, so it has some intensity values.
73

37

00:03:32,150  -->  00:03:40,739
All right, so that means for instance the
the high intensity values like this
75

38

00:03:40,739  -->  00:03:46,829
one where I am means there is
potential motion in this area here, while
77

39

00:03:46,829  -->  00:03:52,819
the blacks areas imply there is no
motion, but you also see some light black
79

40

00:03:52,819  -->  00:03:59,060
pixels here because when i when I appear
on camera there is shadow behind me and so on.
81

41

00:03:59,060  -->  00:04:06,030
But we will apply something else later on
which is called the threshold, so we'll
83

42

00:04:06,030  -->  00:04:09,450
basically say that if you see adifference
in the delta frame, in the frame
85

43

00:04:09,450  -->  00:04:14,639
that I just showed you, if you see
a difference of more than 100 intensity
87

44

00:04:14,639  -->  00:04:21,609
convert that pixels, those pixels
to white pixels, okay.
89

45

00:04:21,609  -->  00:04:28,719
And for pixels that are below the
threshold convert them to black, okay.
91

46

00:04:28,719  -->  00:04:34,300
So you come up with the outline of the
object that is moving in the camera,
93

47

00:04:34,300  -->  00:04:40,210
in the frame. So we're doing all these
processes, inside the while loop and then
95

48

00:04:40,210  -->  00:04:44,409
once we have calculated the threshold frame
inside the loop what we'll do to the
97

49

00:04:44,409  -->  00:04:51,490
current frame is will find the contours
of the white objects in the frame, okay.
99

50

00:04:51,490  -->  00:04:57,610
So for this particular image we would have
contours around this object here, and the
101

51

00:04:57,610  -->  00:05:02,199
contours around this, and around this is as well,
and then we'll write a for loop that will
103

52

00:05:02,199  -->  00:05:07,150
iterate through all the contours of the
current frame, okay, it will go to this contur,
105

53

00:05:07,150  -->  00:05:11,919
to this, to this, and to this one, and then
inside that loop what we will do, is we will
107

54

00:05:11,919  -->  00:05:18,279
check if the area of the contours, so this
for example has an area of let's say 500
109

55

00:05:18,279  -->  00:05:24,430
pixels, so if the area of the
contour is more than 500 pixels for
111

56

00:05:24,430  -->  00:05:30,159
example, then consider this as a moving
moving object. If there is let's say less
113

57

00:05:30,159  -->  00:05:35,379
than 500 like this one here is probably
20 pixels let's say, this will not be
115

58

00:05:35,379  -->  00:05:41,169
considered a moving object, okay, I hope
that makes sense, and then what we'll do
117

59

00:05:41,169  -->  00:05:46,900
next is we'll draw a rectangle around
the contours that were greater than the
119

60

00:05:46,900  -->  00:05:53,020
minimum area and I will show those
rectangles in original image, so in the
121

61

00:05:53,020  -->  00:05:58,389
color version of the current frame, and that
means we will see a rectangle in the
123

62

00:05:58,389  -->  00:06:01,509
video while the video is playing
we will see rectangle around the object.
125

63

00:06:01,509  -->  00:06:06,339
Later on we will detect the times that
the object, the moving object entered
127

64

00:06:06,339  -->  00:06:11,830
the background, the video frame, and the time
that the object exited the background.
129

65

00:06:11,830  -->  00:06:16,719
But for now let's simply focus on
detecting the object, the moving object
131

66

00:06:16,719  -->  00:06:23,639
in the video. Okay.
Let's go back to the script.
133

67

00:06:26,430  -->  00:06:34,770
Close this and this and this. Okay and let's
remove some unnecessary lines here.
135

68

00:06:34,770  -->  00:06:39,180
So we had the a variable here which we
created because we wanted to see how
137

69

00:06:39,180  -->  00:06:45,539
many frames we had in the video, so we
don't need that anymore, and we don't
139

70

00:06:45,539  -->  00:06:51,000
need the script to stop for three seconds.
So I remove the time.sleep.
141

71

00:06:51,000  -->  00:06:59,100
And this one as well. Okay, and now here the
first part is the most trickiest one.
143

72

00:06:59,100  -->  00:07:04,650
We need to figure out a way to store the
current frame of the video so as soon as
145

73

00:07:04,650  -->  00:07:10,380
the video starts we want to store that
Numpy array in a variable and have that
147

74

00:07:10,380  -->  00:07:14,160
variable static, so we don't want to
change the value of the variable while
149

75

00:07:14,160  -->  00:07:20,310
the while loop runs in the script.
The way to do that is we would first
151

76

00:07:20,310  -->  00:07:28,259
need to create a variable for the frame,
for the first frame, so we need to assign it
153

77

00:07:28,259  -->  00:07:35,340
a None value, so None is a special Python
data type that allows you to create a
155

78

00:07:35,340  -->  00:07:39,270
a variable and assign nothing to it but
you have the variable there, so if you call
157

79

00:07:39,270  -->  00:07:44,940
this variable later Python will not say
variable is not defined. Okay, if you
159

80

00:07:44,940  -->  00:07:51,510
don't understand it, please hold on and
you will get it in just a while. And what you
161

81

00:07:51,510  -->  00:07:57,650
need to do now is to write a conditional
and apply a continue statement in there.
163

82

00:07:57,650  -->  00:08:02,580
Let me write the conditional first and
then I'll explain to you what this does.
165

83

00:08:02,580  -->  00:08:17,880
So we want to check if the first frame
is None and if it is None we will assign
167

84

00:08:17,880  -->  00:08:27,750
the first frame the gray frame.
So what this does is that the scrip will
169

85

00:08:27,750  -->  00:08:33,870
run, the video will be triggered and then the
while loop will start to run and it will get
171

86

00:08:33,870  -->  00:08:38,710
the first frame of the video, and it will
store it in this frame variable,
173

87

00:08:38,710  -->  00:08:43,000
and this frame variable will be
converted into a gray frame and then we
175

88

00:08:43,000  -->  00:08:48,520
say if the first frame is None, which is
true in the first iteration of the loop
177

89

00:08:48,520  -->  00:08:53,140
this is true, so the first frame is
actually None because we assigned None
179

90

00:08:53,140  -->  00:09:00,310
here, assign the gray numpy to the
first frame. So the first frame will get
181

91

00:09:00,310  -->  00:09:06,310
the grayscale image which represents the
very first frame of the video. So this
183

92

00:09:06,310  -->  00:09:12,730
happens in the very first iteration of the
loop, okay? But then, what will happen is
185

93

00:09:12,730  -->  00:09:17,980
Python will execute these other lines of
code and then it will go to the second loop
187

94

00:09:17,980  -->  00:09:23,470
and what Python will do is it will grab
the second frame of the video, okay?
189

95

00:09:23,470  -->  00:09:28,810
Let's say the first frame was a background
image, then suddenly an object appears in
191

96

00:09:28,810  -->  00:09:34,450
the camera, in front of the camera so
Python will grab the numpy array that
193

97

00:09:34,450  -->  00:09:39,760
contains that object, so the second frame
and this frame will be converted to gray
195

98

00:09:39,760  -->  00:09:46,060
and then here we say if first frame is None,
the first frame variable will get the
197

99

00:09:46,060  -->  00:09:52,600
first frame of the video and once we
have grabbed the first frame we don't
199

100

00:09:52,600  -->  00:09:57,700
want this other lines of code to be
executed because here we will have, you
201

101

00:09:57,700  -->  00:10:01,900
know, we'll apply the difference between
frames and we will blurry the frames and
203

102

00:10:01,900  -->  00:10:07,330
so on, so we don't want these to be
executed, instead we want Python to go to
205

103

00:10:07,330  -->  00:10:12,760
the beginning of the loop and continue
with the second frame. To do that we need
207

104

00:10:12,760  -->  00:10:19,779
to go and write continue here. So this means
continue to the beginning of the loop
209

105

00:10:19,779  -->  00:10:26,829
and don't go and around the rest of the
code, okay, so the first frame is None.
211

106

00:10:26,829  -->  00:10:31,900
The first frame gets this value of the first
image of the video and then goes to the
213

107

00:10:31,900  -->  00:10:37,209
next iteration, and then the next
iteration what will do, it will grab
215

108

00:10:37,209  -->  00:10:42,459
the second frame of the video and then it
will calculate the gray version of that
217

109

00:10:42,459  -->  00:10:48,459
frame and then it goes again to the
conditional, and in this case is the
219

110

00:10:48,459  -->  00:10:51,880
first frame None? No, it's not because
the first frame got the value of the
221

111

00:10:51,880  -->  00:10:54,770
gray image
in the first iteration of the
223

112

00:10:54,770  -->  00:11:00,380
while loop, so this lines here will not
be executed at the second iteration of
225

113

00:11:00,380  -->  00:11:08,440
the loop, okay? Great.
That means we can now apply Delta frame,
227

114

00:11:08,440  -->  00:11:13,580
so we can calculate the difference
between the first frame and the current
229

115

00:11:13,580  -->  00:11:17,090
frame of the image. So the first frame is
the first frame variable and the
231

116

00:11:17,090  -->  00:11:22,850
current frame is a gray variable,
but before that we would like to do
233

117

00:11:22,850  -->  00:11:28,880
something to the current frame of the
image. We want to apply a Gaussian blur
235

118

00:11:28,880  -->  00:11:38,210
to the image. And a dot here.
So the reason we want to apply Gaussian
237

119

00:11:38,210  -->  00:11:42,950
blur is that we want to blur the image
so we want to make it blurry so to
239

120

00:11:42,950  -->  00:11:48,260
smooth it because that removes noise and
increases accuracy in the calculation
241

121

00:11:48,260  -->  00:11:54,110
of the difference, so this gets
parameter the image you want to blur.
243

122

00:11:54,110  -->  00:11:59,030
So we are passing the gray image
here and we're storing the blurry version of
245

123

00:11:59,030  -->  00:12:05,270
the image in a gray image again, and then
we have another parameter which comes as
247

124

00:12:05,270  -->  00:12:12,710
a tuple and here we need to pass a width
and height of a Gaussian kernel, so which
249

125

00:12:12,710  -->  00:12:18,560
is basically the parameters of the
blurriness, but 21 would be accepted numbers.
251

126

00:12:18,560  -->  00:12:23,920
And you also need a number, last parameter
so that would be the standard deviation
253

127

00:12:23,920  -->  00:12:31,550
and pass zero. Zero here is also commonly
used. If you want to learn about them you
255

128

00:12:31,550  -->  00:12:36,830
can go through the documentation but
these values would be good. So we're
257

129

00:12:36,830  -->  00:12:45,650
making the gray image blurry here, then
down here now we need to compare the
259

130

00:12:45,650  -->  00:12:51,500
first frame of the image, so the
background with the current frame.
261

131

00:12:51,500  -->  00:12:59,780
Let's call this delta frame and that would
be equal to cv2.absdifference so
263

132

00:12:59,780  -->  00:13:04,430
absolute difference
between the first frame
265

133

00:13:04,430  -->  00:13:10,010
and the current frame which is gray.
Note that the first frame will also be
267

134

00:13:10,010  -->  00:13:15,740
a gray version, a blurry gray
version actually, so we are comparing
269

135

00:13:15,740  -->  00:13:23,930
here two blurriede grayscale images, okay?
And what this will give us is another
271

136

00:13:23,930  -->  00:13:29,920
image, okay? And actually I would like to
show that image here on the screen.
273

137

00:13:29,920  -->  00:13:42,530
Cv2image show Delta frame. Let's see what
we'll get out of this. And before running
275

138

00:13:42,530  -->  00:13:47,480
the script I'll disappear from the view
first and then will appear again.
277

139

00:13:47,480  -->  00:13:55,720
Let's see. Okay, nothing happened because.
I forgot to enter the name of the window
279

140

00:13:55,720  -->  00:14:07,160
Let's call this delta frame and let's
say gray frame for this. Now let me run
281

141

00:14:07,160  -->  00:14:22,520
it again. And here so this is the blurred
grayscale version, this one here and we
283

142

00:14:22,520  -->  00:14:33,010
have the difference, okay, so you can see
the lamp behind me in the delta frame. Great.
285

143

00:14:33,010  -->  00:14:42,380
Press the Q key and quit the video now
if you if I want to print just to check
287

144

00:14:42,380  -->  00:14:52,220
the delta frame, this will allow us to
see the difference between intensities
289

145

00:14:52,220  -->  00:15:06,529
of the corresponding pixels so let's see.
And if I quit this now
291

146

00:15:06,529  -->  00:15:15,029
here we go. So what we have here five
means there is no difference, so in this
293

147

00:15:15,029  -->  00:15:20,970
area there's no motion probably but then
you have 174 which is quite white,
295

148

00:15:20,970  -->  00:15:28,769
so that means Python will classify
this as motion. Okay, that was just to show
297

149

00:15:28,769  -->  00:15:37,529
you the values of the delta frame. What
we need now is to classify these values.
299

150

00:15:37,529  -->  00:15:41,940
So let's say we want to assign
a threshold, so let's say if you have
301

151

00:15:41,940  -->  00:15:45,899
values that are more than 30, so if
the difference between the first frame
303

152

00:15:45,899  -->  00:15:52,860
and the current frame is more than 30,
we will classify that as white.
305

153

00:15:52,860  -->  00:15:58,019
So we will say there's probably motioning
in those pixels, so there's an object in
307

154

00:15:58,019  -->  00:16:03,779
those pixels, and if the difference is
less than thirty we'll assign it black
309

155

00:16:03,779  -->  00:16:12,180
pixels, okay? So we can do that so we are
here, we can do that using the
311

156

00:16:12,180  -->  00:16:20,000
threshold method of the cv2 library.
Let's say thresh_delta equals to
313

157

00:16:20,000  -->  00:16:31,019
cv2.threshold, and what this expects is a image
that you want to threshold and then you
315

158

00:16:31,019  -->  00:16:36,839
want to specify a threshold limit.
So 30, we said 30. And what color do
317

159

00:16:36,839  -->  00:16:40,860
you want to assign to the values that
are more than 30? Well we want to saw
319

160

00:16:40,860  -->  00:16:48,570
in a white color which corresponds to
the 255 value, okay? And you also need
321

161

00:16:48,570  -->  00:16:56,490
one more argument here which is the
threshold method. There are quite a few
323

162

00:16:56,490  -->  00:17:03,209
methods out there, but we are using
this method here, so threshold binary.
325

163

00:17:03,209  -->  00:17:06,949
You can experiment with others if you like.
Great and now let's see how this thresh
327

164

00:17:10,860  -->  00:17:17,189
Delta frame will look like. Cv2.imshow
threshold frame.
329

165

00:17:17,189  -->  00:17:28,769
Okay, thresh_delta.
Great, let's see!
331

166

00:17:31,620  -->  00:17:42,909
apparently I wrote this wrongly. Delta
frame, not frame Delta. And one more
333

167

00:17:42,909  -->  00:17:52,450
typo in line 19 which is here, cv2, okay.
Let's hope this time will work, and yet
335

168

00:17:52,450  -->  00:18:01,210
another error. And this time I've missed
something here. Okay, this method here so
337

169

00:18:01,210  -->  00:18:06,610
the threshold method actually returns
a tuple with two values, and the first
339

170

00:18:06,610  -->  00:18:11,950
value is it's needed when you use other
threshold methods, so the first item or
341

171

00:18:11,950  -->  00:18:16,179
the topple basically suggests a value
for threshold if you're using other
343

172

00:18:16,179  -->  00:18:21,100
methods, but for financial binary you
only need to access the second item of
345

173

00:18:21,100  -->  00:18:27,490
the tuple which is the actual frame
that is returned from the threshold
347

174

00:18:27,490  -->  00:18:33,820
method, so you want to access the second
item of the tuple. Okay, I promise this
349

175

00:18:33,820  -->  00:18:49,419
is a last error. Great, finally! And this
is the threshold frame, so you can see my
351

176

00:18:49,419  -->  00:18:54,789
outline there, but you also see some
shadows. So I am being detected as an
353

177

00:18:59,740  -->  00:19:05,409
object, but my shadows as well are
being detected as on objects too. Okay.
355

178

00:19:05,409  -->  00:19:11,019
So you get the idea. Now we can go right
away and use this Thresh Delta frame
357

179

00:19:11,019  -->  00:19:16,629
which I called it thresh Delta. I should
call it the thresh frame, you know, just
359

180

00:19:16,629  -->  00:19:23,889
for name consistency. So we can go ahead
now and create contours of the white
361

181

00:19:23,889  -->  00:19:29,590
objects in the thresh frame, but before that
I would like to do something else.
363

182

00:19:29,590  -->  00:19:33,670
I would like to dilate those areas.
So I want to remove the black holes
365

183

00:19:33,670  -->  00:19:39,490
from those big white areas in the
image, so basically I want to smooth my
367

184

00:19:39,490  -->  00:19:45,550
threshold frame, and to do that you need
to use the dilate method of the cv2
369

185

00:19:45,550  -->  00:19:56,680
library, so let's say we want to change
the threshold frame. Cv2.dilate. Again you
371

186

00:19:56,680  -->  00:20:02,350
want to pass the threshold frame there. Now
if you have a kernel array and you want
373

187

00:20:02,350  -->  00:20:07,270
this process to be very sophisticated
you'd pass that array in here. We don't
375

188

00:20:07,270  -->  00:20:12,550
have any and we don't need one, so you
need to pass None for this parameter and
377

189

00:20:12,550  -->  00:20:18,430
there's yet another parameter here.
Iterations and let's say two, so this
379

190

00:20:18,430  -->  00:20:23,620
defines how many times do you want to go
through the image to remove those holes.
381

191

00:20:23,620  -->  00:20:29,110
So the bigger this number is, the smoother
this image will be. Okay. Now let me
383

192

00:20:29,110  -->  00:20:37,060
check it quickly. Oh yeah, I changed
the name earlier, but I didn't change it
385

193

00:20:37,060  -->  00:20:54,750
here in the imshow method. Thresh frame.
Okay, so you can probably notice that
387

194

00:20:54,750  -->  00:21:04,600
the areas, the white areas are smoother now
so if I go away you'll only notice a few areas
389

195

00:21:04,600  -->  00:21:11,200
that are there because of my shadow, so
it seems to be working so far. Let's quit
391

196

00:21:11,200  -->  00:21:19,750
it now. Great, so we've got these three
frames and what's next? Well next is we
393

197

00:21:19,750  -->  00:21:26,920
need to find the contours of this
dilated threshold frame. Regarding
395

198

00:21:26,920  -->  00:21:33,700
contour detection with openCV you have
two methods, so you have a find contours
397

199

00:21:33,700  -->  00:21:40,240
and a draw contours method. And with the
find conturs method what you do is you
399

200

00:21:40,240  -->  00:21:45,470
find the contours in your image and you
store them in a tuple, on the other hand
401

201

00:21:45,470  -->  00:21:51,590
the draw contours method draws contours in
an image, so in this case what we want to do
403

202

00:21:51,590  -->  00:21:57,920
is we want to find the contours and then
we want to check if the area of this
405

203

00:21:57,920  -->  00:22:02,960
contour, so let's say you have a contour
like a circle and so you want to find
407

204

00:22:02,960  -->  00:22:08,780
the area that this also defines, so you
want to store those contours in
409

205

00:22:08,780  -->  00:22:13,910
a tuple and that's quite a weird syntax
here, but bear with me.
411

206

00:22:13,910  -->  00:22:20,660
So you want to write underscore comma
cnts comma and another underscore.
413

207

00:22:20,660  -->  00:22:27,200
And if you were in OpenCV2 you
wouldn't need the first underscore and
415

208

00:22:27,200  -->  00:22:32,960
the first comma, so you'd have this in
OpenCV2 with Python 2. If you
417

209

00:22:32,960  -->  00:22:39,050
have OpenCv3 with Python 3 this
is what you need to write. Okay, and that
419

210

00:22:39,050  -->  00:22:48,980
would be equal to cv2.findContours.
And then you want to pass afraid that
421

211

00:22:48,980  -->  00:22:55,940
you want to find the contours for. And it's
good to actually use the copy of the frame
423

212

00:22:55,940  -->  00:23:02,480
so you don't want to modify the
threshold frame, so use copy here.
425

213

00:23:02,480  -->  00:23:09,020
So this is the first parameter, the frame
you want to find contours from, and then
427

214

00:23:09,020  -->  00:23:18,950
you have the method retrieve external.
So you want to draw the external contours
429

215

00:23:18,950  -->  00:23:24,080
of the objects that you'll be fining in the
image, and you've got yet another
431

216

00:23:24,080  -->  00:23:34,700
argument. Chain_aprox_simple. So this is
approximation method that OpenCV will
433

217

00:23:34,700  -->  00:23:42,890
apply for retriving the conturs, great.
So what we have is we are iterating
435

218

00:23:42,890  -->  00:23:47,240
through the current frame so we are
blurring it, and converting it to
437

219

00:23:47,240  -->  00:23:53,650
grayscale, and find a data frame,
and apply the thresholds, so the black
439

220

00:23:53,650  -->  00:23:59,830
black and white image, and then we find
all the contours of the objects, of the
441

221

00:23:59,830  -->  00:24:05,860
distinct objects in this image so if
you've got two white continuous areas in
443

222

00:24:05,860  -->  00:24:10,660
your image but they are distinct, you'll get
two contours, so one contour for each of
445

223

00:24:10,660  -->  00:24:18,010
the areas, and these corners will be stored
in this, cnts variable. So we're talking
447

224

00:24:18,010  -->  00:24:22,510
about the current frame, and that's what
we want to do, is we want to filter out
449

225

00:24:22,510  -->  00:24:27,310
these contours, so we want to check that we
want to keep only the contours that are,
451

226

00:24:27,310  -->  00:24:33,550
let's say that have an area that is
bigger than 100, 1000 pixels. For that you
453

227

00:24:33,550  -->  00:24:50,520
need to iterate. Let's say for contour
in cnts, and if cv2.contour area of
455

228

00:24:50,520  -->  00:24:57,280
the contour, so the contour that we are
iterating through, so if this is less
457

229

00:24:57,280  -->  00:25:06,330
than 1000, continue to the beginning of
the for loop again. So what this means is
459

230

00:25:06,330  -->  00:25:11,530
let's say Python found three contours and
it will go through the first one and it
461

231

00:25:11,530  -->  00:25:15,700
will say if the area of this contour, so
we use the contour area of the cv2
463

232

00:25:15,700  -->  00:25:22,870
library, if the area has less than
1000 pixels, go to the next contour, so go
465

233

00:25:22,870  -->  00:25:28,240
to the second contour and check again,
and again, and again. Otherwise if the area
467

234

00:25:28,240  -->  00:25:33,700
is bigger than, or equal to 1000, the next
lines here after the for loop will be
469

235

00:25:33,700  -->  00:25:41,460
executed. So what do you want to do
if a contour is greater than 1000 pixels?
471

236

00:25:41,460  -->  00:25:47,290
Well we want to draw the rectangle
surrounding that contour to the
473

237

00:25:47,290  -->  00:25:54,970
current frame, so make sure you are
inside the for loop,
475

238

00:26:00,180  -->  00:26:08,070
So these are the parameters that define
the rectangle and that would be equal to
477

239

00:26:08,070  -->  00:26:19,740
cv2.boundRectangle of the current
contour, so if the contour is equal or
479

240

00:26:19,740  -->  00:26:25,110
greater than 1000 pixels, so if I it
has an a of equal, or greater
481

241

00:26:25,110  -->  00:26:31,730
than 1000 pixels, this will be executed.
So we are creating a rectangle and then
483

242

00:26:31,730  -->  00:26:37,910
we want to draw that rectangle to our
frame, to our current frame so cv2
485

243

00:26:37,910  -->  00:26:44,780
rectangle, so we already consumed this
method in our face detection lectures.
487

244

00:26:44,780  -->  00:26:51,720
And here we would want to pass the
color frame. Okay, so that is the frame
489

245

00:26:51,720  -->  00:26:59,490
and we want to specify x and y here, so these
are the coordinates of upper left corner of
491

246

00:26:59,490  -->  00:27:06,420
the rectangle. X, y and you want to
specify the coordinates of the right
493

247

00:27:06,420  -->  00:27:18,480
lower corner of the rectangle as well so
X W, just like that. And also the color of
495

248

00:27:18,480  -->  00:27:27,720
your rectangle. Let's say green and the width.
Let's say 3, so what we did in these two
497

249

00:27:27,720  -->  00:27:35,520
lines is that we created this tuple
with this four coordinates and these values,
499

250

00:27:35,520  -->  00:27:41,520
these will be assigned automatically, so x
and y will get the value from
501

251

00:27:41,520  -->  00:27:47,490
the rectangle bounding this contour,
this current contour of the for loop.
503

252

00:27:47,490  -->  00:27:51,060
And then these values will be used to draw
a rectangle in the frame, in the current
505

253

00:27:51,060  -->  00:27:56,880
frame, and then we want to show that
current frame. So let me edit here.
507

254

00:27:56,880  -->  00:28:04,850
Image show. Let's call
this color frame. And frame.
509

255

00:28:04,850  -->  00:28:13,700
Actually this method here is boundingRect.
Let me try the script now.
511

256

00:28:16,810  -->  00:28:26,660
And cv2 has no attribute find countours.
co here I've got a u there
513

257

00:28:26,660  -->  00:28:38,300
that shouldn't be there.
Let's try it again. Yep, that's funny.
515

258

00:28:38,300  -->  00:28:51,230
I tend to mistype this word. Countour area
in line 24 and remover the u. It should be
517

259

00:28:51,230  -->  00:28:55,120
contour here as well.
okay, countour is not defined again. I've
519

260

00:29:06,440  -->  00:29:19,130
got another one here, so bear with me.
Try again and yeah, this time seems to be
521

261

00:29:19,130  -->  00:29:33,260
working. So no objects, objects. No objects,
objects, great. Great, so that's what I
523

262

00:29:33,260  -->  00:29:37,760
want to teach you in this lecture and
we'll continue in the next lectures
525

263

00:29:37,760  -->  00:29:42,500
because what we've done so far
is that we can detect that object and we
527

264

00:29:42,500  -->  00:29:47,030
can draw a rectangle around that object,
but this is not very practical. I mean in
529

265

00:29:47,030  -->  00:29:52,010
real world it's not enough to just draw a
rectangle around your object
531

266

00:29:52,010  -->  00:29:55,430
and then that's it.
So what we'll be doing in the next
533

267

00:29:55,430  -->  00:30:01,040
lecture is will be storing the times
that the object enters the frame and when
535

268

00:30:01,040  -->  00:30:07,130
the object exits the frame, so we've got some
more lines to add to this code and I
537

269

00:30:07,130  -->  00:30:13,880
know this code here was quite a lot to
consume, but I hope these are clear now.
539

270

00:30:13,880  -->  00:30:18,830
If you have any questions please
feel free to ask them and I'll see you
541

271

00:30:18,830  -->  00:30:19,000
in the next lecture.
